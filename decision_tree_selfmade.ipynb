{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(testing, tree, titles):\n",
    "    incorrect = {\"vgood good\": 0, \"vgood acc\": 0,\"vgood unacc\": 0,\n",
    "                  \"good vgood\": 0, \"good acc\": 0, \"good unacc\": 0,\n",
    "                  \"acc vgood\": 0, \"acc good\": 0, \"acc unacc\": 0,\n",
    "                 \"unacc vgood\": 0, \"unacc good\": 0, \"unacc acc\": 0}\n",
    "\n",
    "    correct = {\"vgood\": 0, \"good\": 0, \"acc\": 0, \"unacc\": 0}\n",
    "\n",
    "    for i, row in enumerate(testing):\n",
    "        # for pool of predictions\n",
    "        # print(\"Actual: %s. Predicted: %s\" % (row[-1], print_leaf(classify([titles, row], tree))))\n",
    "        predicted = classify([titles, row], tree)\n",
    "        if predicted is None:\n",
    "            continue\n",
    "        print(\"Actual: %s. Predicted: %s\" % (row[-1], predicted))\n",
    "        if predicted == row[-1]:\n",
    "            correct[predicted] += 1;\n",
    "        else:\n",
    "            if str(row[-1]) + ' ' + predicted in incorrect.keys():\n",
    "                incorrect[str(row[-1]) + ' ' + predicted] += 1\n",
    "    return correct, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(data):\n",
    "    total = 0\n",
    "    for value in data:\n",
    "        total += (-value)/sum(data) * math.log(value/sum(data), 2)\n",
    "    return round(total, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_a(X_train, y_train, i):\n",
    "    # \n",
    "    total = 0\n",
    "    target_column_counts = Counter(X_train.iloc[:,i])\n",
    "    item_names = [value[0] for value in target_column_counts.items()]\n",
    "    item_counts = [value[1] for value in target_column_counts.items()]\n",
    "    for j, item_name in enumerate(item_names):\n",
    "        categoryClasses = Counter(y for x, y in zip(X_train.iloc[:,3], y_train) if x == item_name)\n",
    "        test = [value[1] for value in categoryClasses.items()]\n",
    "        total += item_counts[j]/sum(item_counts) * info(test)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gain(dictionary, class_entropy):\n",
    "    gain = 0\n",
    "    best_attribute = \"\"\n",
    "    for attribute in dictionary:\n",
    "        if class_entropy - dictionary[attribute] >= gain:\n",
    "            gain = class_entropy - dictionary[attribute]\n",
    "            best_attribute = attribute\n",
    "    return best_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root(X_train, y_train):\n",
    "    # Counts values of target attribute\n",
    "    classifier = Counter(y_train)\n",
    "    # Seperate counts into list of values\n",
    "    class_values = [value[1] for value in classifier.items()]\n",
    "    # Calculate entropy for the dataset\n",
    "    class_entropy = info(class_values)\n",
    "    dictionary = {}\n",
    "    for i in range(len(X_train.columns)):\n",
    "        dictionary[i] = info_a(X_train, y_train, i)\n",
    "    return gain(dictionary, class_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self, branches):\n",
    "        self.branches = branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf_Node:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        total_count = len(X_train)\n",
    "        probability = Counter(y_train)\n",
    "        for key in probability:\n",
    "            probability[key] = round((probability[key] / total_count), 3)\n",
    "        self.predictions = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, Leaf_Node):\n",
    "        print(spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    #print(spacing + \"CHECK: \" + str(node.best_attr))\n",
    "\n",
    "\n",
    "    for branch in node.branches:\n",
    "        print(spacing + \"--> IF \" + branch)\n",
    "        print_tree(node.branches[branch], spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, node):\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf_Node):\n",
    "        # Uncomment if you would like to see pool of prediction\n",
    "        #return node.predictions\n",
    "\n",
    "        # Most likely prediction\n",
    "        temp = sorted(node.predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "        return temp[0][0]\n",
    "\n",
    "    #recursion through each dicision node\n",
    "    for branch in node.branches:\n",
    "        decision = branch.split()\n",
    "        index = data[0].index(decision[0])\n",
    "        if data[1][index] == decision[1]:\n",
    "            return classify(data, node.branches[branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(correct, testSize):\n",
    "    return correct / testSize * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #import data\n",
    "    df = pd.read_csv(\"preprocessed_age.csv\")\n",
    "    \n",
    "\n",
    "    # Attribute for classification\n",
    "    target_column = \"Manner of death\"\n",
    "    # Remove NaN\n",
    "    df = df.dropna(subset=[target_column])\n",
    "\n",
    "    df = df.drop([\"Unnamed: 0\", \"Id\", \"Death year\"], axis=1)\n",
    "\n",
    "    # Covert values to numerical\n",
    "    le = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if (df[column].dtype != \"int64\"):\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "\n",
    "    # Split data (train/test)\n",
    "    y = df[target_column]\n",
    "    X = df.drop(target_column, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95)\n",
    "\n",
    "    root = get_root(X_train, y_train)\n",
    "    print(root)\n",
    "    titles = X_train.columns\n",
    "    print(len(X_train))\n",
    "    print(len(y_train))\n",
    "    tree = build_tree(X_train, y_train, 6, titles)\n",
    "    print_tree(tree)\n",
    "    # accuracy_plot = []\n",
    "    # size_plot = []\n",
    "    # #loop through sample sizes - increment 100\n",
    "    # for i in range(1, int(len(X_train) / 100)):\n",
    "    #     size = 100 * i\n",
    "    #     if size > len(X_train):\n",
    "    #         size = len(X_train)\n",
    "    #     temp = random.sample(X_train, k=size)\n",
    "    #     root = get_root(temp)\n",
    "    #     tree = build_tree(temp, root, titles)\n",
    "    #     correct, incorrect = run_testing(testing, tree, titles)\n",
    "    #     accuracy_plot.append(accuracy(sum(correct.values()), len(testing)))\n",
    "    #     size_plot.append(size)\n",
    "\n",
    "    # #create graph\n",
    "    # x1 = size_plot\n",
    "    # y1 = accuracy_plot\n",
    "\n",
    "    # plt.plot(x1, y1, marker='o')\n",
    "    # plt.title(\"Learning Curve\")\n",
    "    # plt.xlabel(\"Number of Samples\")\n",
    "    # plt.ylabel(\"Accuracy %\")\n",
    "    # plt.show()\n",
    "\n",
    "    # #final tree\n",
    "    # root = get_root(training)\n",
    "    # tree = build_tree(training, root, titles)\n",
    "\n",
    "    # # Uncomment to print tree\n",
    "    # print_tree(tree)\n",
    "    # correct, incorrect = run_testing(testing, tree, titles)\n",
    "    # print(\"\\n--Complete--\\n\\nTotal accuracy: %.2f\" % (accuracy(sum(correct.values()), len(testing))), \"%\")\n",
    "    # confusion_matrix(correct, incorrect)\n",
    "    # precision = calc_precision(correct, incorrect)\n",
    "    # recall = calc_recall(correct, incorrect)\n",
    "    # f1_score(correct, precision, recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2443\n",
      "2443\n",
      "X_train length: 36 \n",
      "y_train length: 36\n",
      "X_train length: 36 \n",
      "y_train length: 36\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7724\\613272793.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDecision_Node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubNode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7724\\4101428852.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mprint_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# accuracy_plot = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7724\\613272793.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(X_train, y_train, x, titles)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0msubNode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbranch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_titles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDecision_Node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubNode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7724\\613272793.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(X_train, y_train, x, titles)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mf_X_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mn_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mn_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_titles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\James\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5051\u001b[0m             \u001b[1;31m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5052\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5053\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5055\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "def build_tree(X_train, y_train, x, titles):\n",
    "    class_values = Counter(y_train)\n",
    "    class_count = [value[1] for value in class_values.items()]\n",
    "    class_entropy = info(class_count)\n",
    "\n",
    "    #adjust value to prune tree\n",
    "    if class_entropy <= 0.5:\n",
    "        #create leaf labeelled by majority class in x\n",
    "        return Leaf_Node(X_train, y_train)\n",
    "\n",
    "    # Splitting node into attribute values\n",
    "    attribute_values = Counter(X_train.iloc[:, x])\n",
    "    subNode = {}\n",
    "    for branch in attribute_values:\n",
    "\n",
    "        # Splices data (removes all values that arent branch)\n",
    "\n",
    "        f_X_train = copy.deepcopy(X_train)\n",
    "        f_Y_train = copy.deepcopy(y_train)\n",
    "        f_Y_train = f_Y_train[f_X_train.iloc[:,x] == branch]\n",
    "        f_X_train = f_X_train[f_X_train.iloc[:,x] == branch]\n",
    "        \n",
    "        print(\"X_train length:\", len(f_X_train), \"\\ny_train length:\", len(f_Y_train))\n",
    "        \n",
    "\n",
    "        # Counter of classifier for branch\n",
    "        new_values = Counter(f_Y_train)\n",
    "        new_values_count = [value[1] for value in new_values.items()]\n",
    "\n",
    "        split_entropy = info(new_values_count)\n",
    "        dictionary = {}\n",
    "        # Drop x column\n",
    "        f_X_train = f_X_train.drop(f_X_train.columns[x], axis=1)\n",
    "        n_titles = copy.deepcopy(titles)\n",
    "        n_titles = n_titles.drop(n_titles[x])\n",
    "        for i in range(len(titles)):\n",
    "            dictionary[i] = info_a(X_train, y_train, i)\n",
    "        subNode[titles[x] + \" \" + branch] = build_tree(X_train, y_train, gain(dictionary, split_entropy), n_titles)\n",
    "    return Decision_Node(subNode)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             int64\n",
       "Id                                    object\n",
       "Name                                  object\n",
       "Gender                                object\n",
       "Occupation                            object\n",
       "Birth year                             int64\n",
       "Death year                             int64\n",
       "Manner of death                       object\n",
       "Age of death                           int64\n",
       "Associated Countries                  object\n",
       "Associated Country Life Expectancy    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"preprocessed_age.csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
